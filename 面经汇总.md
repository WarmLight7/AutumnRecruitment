# DB

## 百度搜索架构工程师

### C++封装 继承 和虚函数表的介绍

1. **封装 (Encapsulation)**： 封装是面向对象编程中的一个核心概念，它指的是将数据和操作数据的方法（函数）捆绑在一起，形成一个单一的单元，同时对外部隐藏数据的具体实现细节。通过封装，我们可以限制对数据的直接访问，只允许通过定义好的接口（公有成员函数）来访问和修改数据。这样可以提高代码的安全性、可维护性和可扩展性。

在C++中，可以使用访问修饰符（如`public`、`private`、`protected`）来控制成员变量和成员函数的访问权限。公有成员可以在类的外部访问，私有成员只能在类的内部访问。

1. **继承 (Inheritance)**： 继承是指一个类（称为派生类或子类）可以从另一个类（称为基类、父类或超类）继承属性和方法的过程。继承允许子类重用基类的代码，并且可以通过添加新的属性和方法来扩展或修改基类的功能。继承创建了一个类层次结构，可以通过继承实现代码的重用和分层组织。

在C++中，可以使用关键字 `class` 后面加上冒号，然后紧跟基类的名称来实现继承。不同的继承方式（公有、私有、保护继承）决定了派生类对基类成员的访问权限。

1. **虚函数表 (Virtual Function Table)**： 虚函数表是一种机制，用于实现多态性（Polymorphism）的关键部分。多态性指的是同一方法名可以根据上下文选择不同的实现，这对于处理基类和派生类的对象非常有用。

在C++中，当一个类中包含至少一个虚函数时，编译器会为该类创建一个虚函数表。虚函数表是一个存储了虚函数地址的数组，每个派生类都会有自己的虚函数表，其中包含了该类所覆盖的虚函数的地址。这使得在运行时能够根据对象的实际类型来调用正确的虚函数实现，实现多态性。

需要注意的是，基类中的虚函数应该使用 `virtual` 关键字来声明，而派生类中重写这些虚函数时也要使用 `virtual` 关键字（尽管在派生类中可以省略）。

#### 分别的应用场景

封装和继承是面向对象编程的两个基本概念，它们在不同的应用场景中发挥着重要作用。

**封装的应用场景**：

1. **隐藏实现细节**：通过封装，可以将类的内部实现细节隐藏起来，只暴露必要的接口给外部使用。这有助于降低模块之间的耦合度，使得代码更加可维护和可理解。
2. **数据安全性**：通过将成员变量私有化，并通过公有的成员函数来访问和修改这些变量，可以防止外部直接访问数据，从而提高数据的安全性和完整性。
3. **接口定义**：封装提供了一个清晰的界面，通过这些接口，用户可以使用类的功能而无需关心其内部实现。这使得类的使用更加方便和直观。
4. **代码重用**：封装使得代码可以模块化，易于复用。通过定义好的类和接口，可以在不同的项目中重用已有的代码。

**继承的应用场景**：

1. **代码重用**：继承是实现代码重用的关键手段之一。通过从已有的类派生出子类，可以继承基类的属性和方法，减少重复编写相似的代码。
2. **多态性**：继承与虚函数结合可以实现多态性，即一个方法名可以有多个不同的实现。这对于处理不同类型的对象而要求相同接口的情况非常有用，使得代码更加灵活。
3. **分层结构**：继承可以建立类的层次结构，从而更好地组织和管理代码。基类可以包含通用的属性和方法，而派生类可以在此基础上添加特定的属性和方法。
4. **特化和泛化**：通过继承，可以从一个通用的基类派生出特定领域的子类。例如，从“动物”基类可以派生出“猫”和“狗”等子类，实现更具体的功能。
5. **接口和抽象类**：通过继承抽象类，可以定义一组规范性的接口，从而确保派生类实现了特定的功能。这有助于项目的组织和协作。

#### 成员对象和成员方法位于哪里

成员对象位于类对象的内存里面

成员方法在代码段里

#### 虚函数表的底层

编译器在编译阶段会为每个包含虚函数的类生成一个虚函数表。每个虚函数表中的槽位会存储对应虚函数的地址。如果一个类继承了另一个类的虚函数，它会共享相同的虚函数表，只有在派生类中重写了虚函数，对应的槽位才会被更新为派生类的函数地址。每个使用虚函数的类的对象中，通常会有一个额外的指针（或称为虚指针），指向该对象所属类的虚函数表。这个指针通常位于对象的内存布局的开头处，因此可以方便地访问虚函数表。当通过一个基类指针或引用来调用虚函数时，编译器会通过对象的虚指针查找对应的虚函数表，并从虚函数表中获取正确的虚函数地址，然后进行调用。这使得在运行时能够根据对象的实际类型来调用正确的虚函数实现，实现多态性。

### 常用的C++模板

Vector list deque queue stack set map unordered_map

#### map和unordered_map的区别

**1. 底层实现和数据结构：**

- `std::map`：使用红黑树（Red-Black Tree）作为底层数据结构，它保持键的有序性，即存储的键值对按照键的大小进行排序。
- `std::unordered_map`：使用哈希表（Hash Table）作为底层数据结构，它没有保持键的有序性，存储的键值对在内部通过哈希函数进行散列。

**2. 检索速度：**

- `std::map`：由于红黑树的平衡性质，`std::map` 支持 O(log n) 的平均时间复杂度来查找、插入和删除元素。
- `std::unordered_map`：哈希表的查找时间复杂度通常为 O(1)，但是由于哈希冲突的存在，最坏情况下可能会变成 O(n)。

**3. 有序性：**

- `std::map`：元素按照键的有序性存储，可以通过迭代器遍历得到有序的结果。
- `std::unordered_map`：元素没有特定的顺序，遍历得到的结果可能是无序的。

**4. 内存开销：**

- `std::map`：由于使用红黑树，可能会占用较多的内存，尤其在存储大量数据时。
- `std::unordered_map`：哈希表可能会在一定程度上占用较少的内存，但其哈希函数和冲突解决策略可能会引入一些额外开销。

**5. 哈希冲突：**

- `std::map`：由于使用红黑树，不存在哈希冲突问题。
- `std::unordered_map`：哈希表可能会出现哈希冲突，需要解决冲突的方法，如链表法或开放地址法。

**6. 适用场景：**

- `std::map`：适用于需要有序存储键值对，并且频繁进行插入、删除操作的情况。
- `std::unordered_map`：适用于对查找操作要求较高效率的情况，但不需要保持键的有序性。

#### list和vector区别

**1. 底层实现：**

- `std::list`：使用双向链表作为底层数据结构。每个节点包含一个元素以及指向前一个和后一个节点的指针。
- `std::vector`：使用动态数组（类似于连续内存块）作为底层数据结构。元素在内存中是连续存储的，类似于原生数组。

**2. 插入和删除操作：**

- `std::list`：由于双向链表的特性，插入和删除操作在任意位置都是 O(1) 时间复杂度。
- `std::vector`：插入和删除操作涉及元素的移动，因此在末尾进行操作为平均 O(1)，但在中间或开头则可能需要 O(n) 的时间复杂度。

**3. 随机访问：**

- `std::list`：由于使用链表，随机访问（根据索引查找元素）需要 O(n) 的时间复杂度，因为需要从头或尾开始遍历。
- `std::vector`：由于元素在内存中是连续存储的，随机访问是 O(1) 时间复杂度。

**4. 内存分配：**

- `std::list`：节点之间不需要连续内存，因此分配和释放内存较为灵活。
- `std::vector`：需要连续的内存块，因此可能在动态扩展时需要重新分配内存和拷贝元素，可能导致较大的开销。

**5. 内存占用：**

- `std::list`：由于额外的指针和节点结构，可能会占用较多的内存。
- `std::vector`：通常情况下会更紧凑，只占用存储元素所需的内存空间。

**6. 适用场景：**

- `std::list`：适用于频繁插入和删除操作，不需要随机访问的情况。
- `std::vector`：适用于需要高效随机访问和快速末尾插入的情况。如果插入和删除操作不是主要关注点，并且需要高效的随机访问，通常选择 `std::vector`。



### 进程和线程的区别和联系

1、进程是资源分配的基本单位，运行一个可执行程序会创建一个或多个进程，进程就是运行起来的可执行程序

2、线程是资源调度的基本单位，也是程序执行的基本单位，是轻量级的进程。每个进程中都有唯一的主线程，且只能有一个，主线程和进程是相互依存的关系，主线程结束进程也会结束。多提一句：协程是用户态的轻量级线程，线程内部调度的基本单位

1、线程启动速度快，轻量级

2、线程的系统开销小

3、线程使用有一定难度，需要处理数据一致性问题

4、同一线程共享的有堆、全局变量、静态变量、指针，引用、文件等，而独自占有

5、线程是调度的基本单位（PC，状态码，通用寄存器，线程栈及栈指针）；进程是拥有资源的基本单位（打开文件，堆，静态区，代码段等）

#### 线程编程时需要考虑什么

1.线程同步

2.数据共享

3.死锁避免

4.并发控制

5.线程池管理

6.优先级调度

7.错误处理

#### 条件变量是什么，C++有哪些条件变量控制函数

条件锁（Condition Variable）是多线程编程中用于线程同步的一种机制。它允许线程等待某个特定条件满足后再继续执行，从而避免忙等（busy-waiting）和不必要的资源消耗。条件锁通常与互斥锁（Mutex）一起使用，来实现线程之间的正确协调。

`wait(lock)`：当前线程等待条件满足，同时会释放互斥锁 `lock`，使其他线程能够访问共享资源。当条件满足或者被其他线程调用 `notify_one()` 或 `notify_all()` 唤醒时，线程重新获得锁，并继续执行。

`wait_for(lock, duration)`：与 `wait()` 类似，但可以设置等待的最大时长。如果条件在超时前未满足，线程会重新获得锁并继续执行。

`wait_until(lock, time_point)`：与 `wait_for()` 类似，但可以设置等待的终止时间点。

`notify_one()`：唤醒等待在条件变量上的一个线程，使其继续执行。

`notify_all()`：唤醒等待在条件变量上的所有线程，使它们继续执行。

#### 互斥锁是什么

互斥锁（Mutex，亦称为互斥量）是多线程编程中用于保护共享资源免受并发访问的一种同步机制。它用于确保在任意时刻只有一个线程能够访问被保护的共享资源，从而防止数据竞争和不一致性。

互斥锁的主要目标是避免多个线程同时访问共享资源时可能引发的问题，比如同时读写同一数据、同时修改同一数据等情况。使用互斥锁，只有一个线程能够获得锁，其他线程需要等待，直到持有锁的线程释放锁。

#### 自旋锁是什么与互斥锁的区别是什么

自旋锁是一种简单的同步机制，它不会使线程进入睡眠状态，而是通过不断地循环尝试获取锁，直到成功为止，这就是所谓的自旋。自旋锁适用于临界区很短的情况，其中等待的时间较短。如果等待时间过长，线程一直处于自旋状态，会导致CPU资源的浪费。

互斥锁是一种更高级的同步机制，它会将无法获取锁的线程置于睡眠状态，直到锁可用。互斥锁适用于等待时间较长的情况，因为线程在等待时不会消耗CPU资源，而是会被操作系统调度为非运行状态。

### share_ptr是怎么实现的

`std::shared_ptr` 是 C++ 标准库中的智能指针之一，用于管理动态分配的对象，并在不再需要时自动释放内存。`std::shared_ptr` 使用了引用计数的技术来跟踪有多少个智能指针共享同一个对象，从而在最后一个指针不再需要对象时进行释放。

下面是 `std::shared_ptr` 的一般实现原理：

1. **计数器和对象指针**：每个 `std::shared_ptr` 包含两部分数据，一个指向被管理对象的指针，以及一个引用计数器。
2. **引用计数**：当一个 `std::shared_ptr` 被复制或拷贝构造时，引用计数会递增。当 `std::shared_ptr` 被销毁、赋值或析构时，引用计数会递减。
3. **对象销毁**：当引用计数减少到零时，表示没有任何 `std::shared_ptr` 指向被管理对象，此时释放对象的内存。

```C++
template <typename T>
class SharedPtr {
public:
    // 构造函数
    explicit SharedPtr(T* ptr = nullptr) : ptr_(ptr), ref_count_(new int(1)) {}

    // 拷贝构造函数
    SharedPtr(const SharedPtr& other) : ptr_(other.ptr_), ref_count_(other.ref_count_) {
        (*ref_count_)++;
    }

    // 析构函数
    ~SharedPtr() {
        release();
    }

    // 拷贝赋值运算符
    SharedPtr& operator=(const SharedPtr& other) {
        if (this != &other) {
            release();
            ptr_ = other.ptr_;
            ref_count_ = other.ref_count_;
            (*ref_count_)++;
        }
        return *this;
    }

    // 解引用操作符
    T& operator*() const {
        return *ptr_;
    }

    // 成员访问操作符
    T* operator->() const {
        return ptr_;
    }

private:
    T* ptr_;
    int* ref_count_;

    // 释放资源
    void release() {
        if (--(*ref_count_) == 0) {
            delete ptr_;
            delete ref_count_;
            ptr_ = nullptr;
            ref_count_ = nullptr;
        }
    }
};
```

## 字节Data电商后端开发

### C++和python的语言特点

**C++ 的特点：**

1. **静态类型语言：** C++ 是一种静态类型语言，意味着变量在编译时必须指定其数据类型，并且在运行时类型不会改变。
2. **强类型语言：** C++ 是强类型语言，要求在操作变量之前进行显式的类型转换。
3. **高性能：** C++ 是一种编译型语言，可以生成高效的机器码，因此在性能要求高的场景下表现优异。
4. **内存控制：** C++ 允许对内存进行更精细的控制，包括手动内存分配和释放。但这也可能导致内存泄漏和指针错误。
5. **复杂性：** C++ 的语法和概念相对较复杂，需要开发者有较高的技能水平。

**Python 的特点：**

1. **动态类型语言：** Python 是一种动态类型语言，变量在运行时可以自动推断其类型。
2. **解释型语言：** Python 是解释型语言，不需要编译，代码可以直接运行。这导致一般情况下 Python 运行速度较慢。
3. **简洁易读：** Python 的语法简洁清晰，强调代码的可读性，适合初学者和快速开发。
4. **动态内存管理：** Python 会自动进行内存管理，有垃圾回收机制来处理内存释放，减少了内存泄漏的可能性。
5. **强大的标准库：** Python 提供了丰富的标准库，涵盖了许多常用的任务，如文件操作、网络通信、GUI 开发等。
6. **动态性：** Python 具有更高的动态性，允许运行时修改类和对象，以及进行元编程。
7. **适用领域：** Python 适用于快速开发、数据分析、科学计算、Web 开发、自动化脚本等领域。

### 编译型语言和解释性语言的区别

编译型语言和解释性语言是两种不同的编程语言类型，它们在代码执行的方式和性能等方面存在一些重要区别。

**编译型语言：**

1. **执行过程：** 
   1. 在编译型语言中，源代码在执行之前需要先经过编译器的编译过程。编译器将源代码转换为机器码或中间代码，生成一个可执行文件。
   2. 在解释性语言中，源代码一行一行地被解释器读取并执行。解释器逐行翻译代码并执行操作，不需要生成可执行文件。
2. **执行方式：** 
   1. 执行编译后的可执行文件。在执行时，操作系统不需要再重新解释代码，直接运行生成的机器码。
   2. 解释性语言 源代码直接被解释器执行，无需编译成机器码。
3. **性能：** 
   1. 由于代码在执行之前已经经过了编译过程，编译型语言的执行速度通常较快，因为机器码的执行效率更高。
   2. 解释性语言的执行速度通常较慢，因为每次执行代码都需要解释器进行解释和执行。
4. **开发效率：** 
   1. 编译型语言需要经过编译过程，因此开发的迭代速度相对较慢。每次修改代码后都需要重新编译。
   2. 解释性语言由于无需编译过程，开发的迭代速度相对较快。修改代码后可以立即运行。

### 虚拟内存的作用，实现原理

#### 作用

**虚拟内存简单来说就是把外存当作内存来使用，便于缓解物理内存压力的不足。**所有运行在计算机上的程序都需要通过内存来执行，如果运行的程序占用了大量的内存，将导致内存耗尽。为了解决这个问题，采用了虚拟内存技术，当内存耗尽时，计算机会自动调用硬盘作为内存来缓解内存紧张。**当计算机运行程序或运行所需随机内存不足时，此时虚拟内存就来进行充当数据存储的任务了**

#### 原理

**虚拟存储器由硬件与操作系统自动地实现存储器信息的调度与管理**虚拟内存是给每一个程序设置一个“连续”的虚拟地址空间，把这个地址空间分成若干页，这些页具有连续的地址范围，并在程序运行过程中动态地映射到物理内存中。当程序引用到物理内存地址空间时，硬件就会立刻执行相应的映射，当程序引用到一个地址空间之外的地址空间时，操作系统负责把丢失的部分装入物理内存，并重新执行失败指令。

**虚拟内存的调度方式一般可以分为页式调度、段式调度、段页式调度，不同的调度方式也有着不同的区别。**具体如下：

**页式调度：**

在页式虚拟存储器中，把虚拟空间划分成相同大小的页面，虚拟地址可以由页面表格转化为实体地址。每一个程序都有一个页表，其中的每一个空页数都有一个入口，这个入口至少包括了这个虚页的主存储器（实际页数），并将其用作实际地址的更高的域；将实页编号和虚拟位置的页面内位址合并，就会生成一个完全的实际位址，用以存取主存储器。

**段式调度：**

在段式虚拟存储器中，将虚拟位址分为段数和区段内部位址。每一程式设定一段表，段资料表的每一栏位都包含三个栏位：有效位元（表示区段是否已调至主存）、段起址（区段在实存中的首位址）及段长（纪录区段的实际长度）。

**段页式调度：**

段页式虚拟存储器是段式虚拟存储器和页式虚拟存储器的结合。首先将实存等分为几个页面，在一个片断的虚拟存贮器中，将一个程序按逻辑结构分割开来，然后根据实际页面的大小，对每个页面进行分类，并根据页面的不同，对各个页面进行输入和输出。

### 进程的内存分布

![img](面经汇总.assets/202205212344868.png)

用户空间内存，从**低到高**分别是 7 种不同的内存段：

- 程序文件段，包括二进制可执行代码；
- 已初始化数据段，包括静态常量；
- 未初始化数据段，包括未初始化的静态变量；
- 堆段，包括动态分配的内存，从低地址开始向上增长；
- 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关）
- 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小

#### 函数调用时栈区的状态

栈区主要用于存储函数的局部变量、函数参数、返回地址和临时数据等信息。下面是函数调用期间栈区的一般状态变化：

1. **调用前**：在函数调用之前，栈顶指针指向当前函数的栈帧的顶部。这个栈帧包含了函数的局部变量、参数、返回地址等信息。
2. **函数调用**：当一个函数被调用时，会执行以下步骤：
   - 将函数的参数压入栈中，以便函数在栈中获取参数值。
   - 将返回地址（调用该函数之后要返回的地址）压入栈中。
   - 分配空间用于存储函数的局部变量。
   - 更新栈顶指针，指向新的栈帧。
3. **函数执行**：在函数执行期间，栈帧内的局部变量被使用，可能会被修改。其他栈帧的信息保持不变，等待函数执行完成后恢复。
4. **函数返回**：当函数执行完成后，会执行以下步骤：
   - 从栈中弹出局部变量，释放栈帧内的内存。
   - 弹出返回地址，以便返回到调用函数的正确位置。
   - 更新栈顶指针，回到调用函数的栈帧。







## 红黑树

### 双红优化

1. 叔叔节点黑色：调整完根黑叶子红
   1. 同侧p为根
   2. 异侧x为根往叔叔方向旋转
2. 叔叔节点红色：
   1. 变黑后提高高度递归

### 双黑优化

1. 兄弟节点是黑色并且兄弟节点有红色
   1. 从红色节点往上转
2. 兄弟节点是黑色并且兄弟节点没红色
   1. 兄弟变红并且查父亲，变红或者递归
3. 兄弟节点是红色
   1. 往这边转，同时递归处理








# 目录

[TOC]





# DB师兄

## 百度搜索架构工程师

### C++封装 继承 和虚函数表的介绍

1. **封装 (Encapsulation)**： 封装是面向对象编程中的一个核心概念，它指的是将数据和操作数据的方法（函数）捆绑在一起，形成一个单一的单元，同时对外部隐藏数据的具体实现细节。通过封装，我们可以限制对数据的直接访问，只允许通过定义好的接口（公有成员函数）来访问和修改数据。这样可以提高代码的安全性、可维护性和可扩展性。

在C++中，可以使用访问修饰符（如`public`、`private`、`protected`）来控制成员变量和成员函数的访问权限。公有成员可以在类的外部访问，私有成员只能在类的内部访问。

1. **继承 (Inheritance)**： 继承是指一个类（称为派生类或子类）可以从另一个类（称为基类、父类或超类）继承属性和方法的过程。继承允许子类重用基类的代码，并且可以通过添加新的属性和方法来扩展或修改基类的功能。继承创建了一个类层次结构，可以通过继承实现代码的重用和分层组织。

在C++中，可以使用关键字 `class` 后面加上冒号，然后紧跟基类的名称来实现继承。不同的继承方式（公有、私有、保护继承）决定了派生类对基类成员的访问权限。

1. **虚函数表 (Virtual Function Table)**： 虚函数表是一种机制，用于实现多态性（Polymorphism）的关键部分。多态性指的是同一方法名可以根据上下文选择不同的实现，这对于处理基类和派生类的对象非常有用。

在C++中，当一个类中包含至少一个虚函数时，编译器会为该类创建一个虚函数表。虚函数表是一个存储了虚函数地址的数组，每个派生类都会有自己的虚函数表，其中包含了该类所覆盖的虚函数的地址。这使得在运行时能够根据对象的实际类型来调用正确的虚函数实现，实现多态性。

需要注意的是，基类中的虚函数应该使用 `virtual` 关键字来声明，而派生类中重写这些虚函数时也要使用 `virtual` 关键字（尽管在派生类中可以省略）。

#### 分别的应用场景

封装和继承是面向对象编程的两个基本概念，它们在不同的应用场景中发挥着重要作用。

**封装的应用场景**：

1. **隐藏实现细节**：通过封装，可以将类的内部实现细节隐藏起来，只暴露必要的接口给外部使用。这有助于降低模块之间的耦合度，使得代码更加可维护和可理解。
2. **数据安全性**：通过将成员变量私有化，并通过公有的成员函数来访问和修改这些变量，可以防止外部直接访问数据，从而提高数据的安全性和完整性。
3. **接口定义**：封装提供了一个清晰的界面，通过这些接口，用户可以使用类的功能而无需关心其内部实现。这使得类的使用更加方便和直观。
4. **代码重用**：封装使得代码可以模块化，易于复用。通过定义好的类和接口，可以在不同的项目中重用已有的代码。

**继承的应用场景**：

1. **代码重用**：继承是实现代码重用的关键手段之一。通过从已有的类派生出子类，可以继承基类的属性和方法，减少重复编写相似的代码。
2. **多态性**：继承与虚函数结合可以实现多态性，即一个方法名可以有多个不同的实现。这对于处理不同类型的对象而要求相同接口的情况非常有用，使得代码更加灵活。
3. **分层结构**：继承可以建立类的层次结构，从而更好地组织和管理代码。基类可以包含通用的属性和方法，而派生类可以在此基础上添加特定的属性和方法。
4. **特化和泛化**：通过继承，可以从一个通用的基类派生出特定领域的子类。例如，从“动物”基类可以派生出“猫”和“狗”等子类，实现更具体的功能。
5. **接口和抽象类**：通过继承抽象类，可以定义一组规范性的接口，从而确保派生类实现了特定的功能。这有助于项目的组织和协作。

#### 成员对象和成员方法位于哪里

成员对象位于类对象的内存里面

成员方法在代码段里

#### 虚函数表的底层

编译器在编译阶段会为每个包含虚函数的类生成一个虚函数表。每个虚函数表中的槽位会存储对应虚函数的地址。如果一个类继承了另一个类的虚函数，它会共享相同的虚函数表，只有在派生类中重写了虚函数，对应的槽位才会被更新为派生类的函数地址。每个使用虚函数的类的对象中，通常会有一个额外的指针（或称为虚指针），指向该对象所属类的虚函数表。这个指针通常位于对象的内存布局的开头处，因此可以方便地访问虚函数表。当通过一个基类指针或引用来调用虚函数时，编译器会通过对象的虚指针查找对应的虚函数表，并从虚函数表中获取正确的虚函数地址，然后进行调用。这使得在运行时能够根据对象的实际类型来调用正确的虚函数实现，实现多态性。

### 常用的C++模板

Vector list deque queue stack set map unordered_map

#### map和unordered_map的区别

**1. 底层实现和数据结构：**

- `std::map`：使用红黑树（Red-Black Tree）作为底层数据结构，它保持键的有序性，即存储的键值对按照键的大小进行排序。
- `std::unordered_map`：使用哈希表（Hash Table）作为底层数据结构，它没有保持键的有序性，存储的键值对在内部通过哈希函数进行散列。

**2. 检索速度：**

- `std::map`：由于红黑树的平衡性质，`std::map` 支持 O(log n) 的平均时间复杂度来查找、插入和删除元素。
- `std::unordered_map`：哈希表的查找时间复杂度通常为 O(1)，但是由于哈希冲突的存在，最坏情况下可能会变成 O(n)。

**3. 有序性：**

- `std::map`：元素按照键的有序性存储，可以通过迭代器遍历得到有序的结果。
- `std::unordered_map`：元素没有特定的顺序，遍历得到的结果可能是无序的。

**4. 内存开销：**

- `std::map`：由于使用红黑树，可能会占用较多的内存，尤其在存储大量数据时。
- `std::unordered_map`：哈希表可能会在一定程度上占用较少的内存，但其哈希函数和冲突解决策略可能会引入一些额外开销。

**5. 哈希冲突：**

- `std::map`：由于使用红黑树，不存在哈希冲突问题。
- `std::unordered_map`：哈希表可能会出现哈希冲突，需要解决冲突的方法，如链表法或开放地址法。

**6. 适用场景：**

- `std::map`：适用于需要有序存储键值对，并且频繁进行插入、删除操作的情况。
- `std::unordered_map`：适用于对查找操作要求较高效率的情况，但不需要保持键的有序性。

#### list和vector区别

**1. 底层实现：**

- `std::list`：使用双向链表作为底层数据结构。每个节点包含一个元素以及指向前一个和后一个节点的指针。
- `std::vector`：使用动态数组（类似于连续内存块）作为底层数据结构。元素在内存中是连续存储的，类似于原生数组。

**2. 插入和删除操作：**

- `std::list`：由于双向链表的特性，插入和删除操作在任意位置都是 O(1) 时间复杂度。
- `std::vector`：插入和删除操作涉及元素的移动，因此在末尾进行操作为平均 O(1)，但在中间或开头则可能需要 O(n) 的时间复杂度。

**3. 随机访问：**

- `std::list`：由于使用链表，随机访问（根据索引查找元素）需要 O(n) 的时间复杂度，因为需要从头或尾开始遍历。
- `std::vector`：由于元素在内存中是连续存储的，随机访问是 O(1) 时间复杂度。

**4. 内存分配：**

- `std::list`：节点之间不需要连续内存，因此分配和释放内存较为灵活。
- `std::vector`：需要连续的内存块，因此可能在动态扩展时需要重新分配内存和拷贝元素，可能导致较大的开销。

**5. 内存占用：**

- `std::list`：由于额外的指针和节点结构，可能会占用较多的内存。
- `std::vector`：通常情况下会更紧凑，只占用存储元素所需的内存空间。

**6. 适用场景：**

- `std::list`：适用于频繁插入和删除操作，不需要随机访问的情况。
- `std::vector`：适用于需要高效随机访问和快速末尾插入的情况。如果插入和删除操作不是主要关注点，并且需要高效的随机访问，通常选择 `std::vector`。



### 进程和线程的区别和联系

1、进程是资源分配的基本单位，运行一个可执行程序会创建一个或多个进程，进程就是运行起来的可执行程序

2、线程是资源调度的基本单位，也是程序执行的基本单位，是轻量级的进程。每个进程中都有唯一的主线程，且只能有一个，主线程和进程是相互依存的关系，主线程结束进程也会结束。多提一句：协程是用户态的轻量级线程，线程内部调度的基本单位

1、线程启动速度快，轻量级

2、线程的系统开销小

3、线程使用有一定难度，需要处理数据一致性问题

4、同一线程共享的有堆、全局变量、静态变量、指针，引用、文件等，而独自占有

5、线程是调度的基本单位（PC，状态码，通用寄存器，线程栈及栈指针）；进程是拥有资源的基本单位（打开文件，堆，静态区，代码段等）

#### 线程编程时需要考虑什么

1.线程同步

2.数据共享

3.死锁避免

4.并发控制

5.线程池管理

6.优先级调度

7.错误处理

#### 条件变量是什么，C++有哪些条件变量控制函数

条件锁（Condition Variable）是多线程编程中用于线程同步的一种机制。它允许线程等待某个特定条件满足后再继续执行，从而避免忙等（busy-waiting）和不必要的资源消耗。条件锁通常与互斥锁（Mutex）一起使用，来实现线程之间的正确协调。

`wait(lock)`：当前线程等待条件满足，同时会释放互斥锁 `lock`，使其他线程能够访问共享资源。当条件满足或者被其他线程调用 `notify_one()` 或 `notify_all()` 唤醒时，线程重新获得锁，并继续执行。

`wait_for(lock, duration)`：与 `wait()` 类似，但可以设置等待的最大时长。如果条件在超时前未满足，线程会重新获得锁并继续执行。

`wait_until(lock, time_point)`：与 `wait_for()` 类似，但可以设置等待的终止时间点。

`notify_one()`：唤醒等待在条件变量上的一个线程，使其继续执行。

`notify_all()`：唤醒等待在条件变量上的所有线程，使它们继续执行。

#### 互斥锁是什么

互斥锁（Mutex，亦称为互斥量）是多线程编程中用于保护共享资源免受并发访问的一种同步机制。它用于确保在任意时刻只有一个线程能够访问被保护的共享资源，从而防止数据竞争和不一致性。

互斥锁的主要目标是避免多个线程同时访问共享资源时可能引发的问题，比如同时读写同一数据、同时修改同一数据等情况。使用互斥锁，只有一个线程能够获得锁，其他线程需要等待，直到持有锁的线程释放锁。

#### 自旋锁是什么与互斥锁的区别是什么

自旋锁是一种简单的同步机制，它不会使线程进入睡眠状态，而是通过不断地循环尝试获取锁，直到成功为止，这就是所谓的自旋。自旋锁适用于临界区很短的情况，其中等待的时间较短。如果等待时间过长，线程一直处于自旋状态，会导致CPU资源的浪费。

互斥锁是一种更高级的同步机制，它会将无法获取锁的线程置于睡眠状态，直到锁可用。互斥锁适用于等待时间较长的情况，因为线程在等待时不会消耗CPU资源，而是会被操作系统调度为非运行状态。

### share_ptr是怎么实现的

`std::shared_ptr` 是 C++ 标准库中的智能指针之一，用于管理动态分配的对象，并在不再需要时自动释放内存。`std::shared_ptr` 使用了引用计数的技术来跟踪有多少个智能指针共享同一个对象，从而在最后一个指针不再需要对象时进行释放。

下面是 `std::shared_ptr` 的一般实现原理：

1. **计数器和对象指针**：每个 `std::shared_ptr` 包含两部分数据，一个指向被管理对象的指针，以及一个引用计数器。
2. **引用计数**：当一个 `std::shared_ptr` 被复制或拷贝构造时，引用计数会递增。当 `std::shared_ptr` 被销毁、赋值或析构时，引用计数会递减。
3. **对象销毁**：当引用计数减少到零时，表示没有任何 `std::shared_ptr` 指向被管理对象，此时释放对象的内存。

```C++
template <typename T>
class SharedPtr {
public:
    // 构造函数
    explicit SharedPtr(T* ptr = nullptr) : ptr_(ptr), ref_count_(new int(1)) {}

    // 拷贝构造函数
    SharedPtr(const SharedPtr& other) : ptr_(other.ptr_), ref_count_(other.ref_count_) {
        (*ref_count_)++;
    }

    // 析构函数
    ~SharedPtr() {
        release();
    }

    // 拷贝赋值运算符
    SharedPtr& operator=(const SharedPtr& other) {
        if (this != &other) {
            release();
            ptr_ = other.ptr_;
            ref_count_ = other.ref_count_;
            (*ref_count_)++;
        }
        return *this;
    }

    // 解引用操作符
    T& operator*() const {
        return *ptr_;
    }

    // 成员访问操作符
    T* operator->() const {
        return ptr_;
    }

private:
    T* ptr_;
    int* ref_count_;

    // 释放资源
    void release() {
        if (--(*ref_count_) == 0) {
            delete ptr_;
            delete ref_count_;
            ptr_ = nullptr;
            ref_count_ = nullptr;
        }
    }
};
```

## 字节Data电商后端开发

### C++和python的语言特点

**C++ 的特点：**

1. **静态类型语言：** C++ 是一种静态类型语言，意味着变量在编译时必须指定其数据类型，并且在运行时类型不会改变。
2. **强类型语言：** C++ 是强类型语言，要求在操作变量之前进行显式的类型转换。
3. **高性能：** C++ 是一种编译型语言，可以生成高效的机器码，因此在性能要求高的场景下表现优异。
4. **内存控制：** C++ 允许对内存进行更精细的控制，包括手动内存分配和释放。但这也可能导致内存泄漏和指针错误。
5. **复杂性：** C++ 的语法和概念相对较复杂，需要开发者有较高的技能水平。

**Python 的特点：**

1. **动态类型语言：** Python 是一种动态类型语言，变量在运行时可以自动推断其类型。
2. **解释型语言：** Python 是解释型语言，不需要编译，代码可以直接运行。这导致一般情况下 Python 运行速度较慢。
3. **简洁易读：** Python 的语法简洁清晰，强调代码的可读性，适合初学者和快速开发。
4. **动态内存管理：** Python 会自动进行内存管理，有垃圾回收机制来处理内存释放，减少了内存泄漏的可能性。
5. **强大的标准库：** Python 提供了丰富的标准库，涵盖了许多常用的任务，如文件操作、网络通信、GUI 开发等。
6. **动态性：** Python 具有更高的动态性，允许运行时修改类和对象，以及进行元编程。
7. **适用领域：** Python 适用于快速开发、数据分析、科学计算、Web 开发、自动化脚本等领域。

### 编译型语言和解释性语言的区别

编译型语言和解释性语言是两种不同的编程语言类型，它们在代码执行的方式和性能等方面存在一些重要区别。

**编译型语言：**

1. **执行过程：** 
   1. 在编译型语言中，源代码在执行之前需要先经过编译器的编译过程。编译器将源代码转换为机器码或中间代码，生成一个可执行文件。
   2. 在解释性语言中，源代码一行一行地被解释器读取并执行。解释器逐行翻译代码并执行操作，不需要生成可执行文件。
2. **执行方式：** 
   1. 执行编译后的可执行文件。在执行时，操作系统不需要再重新解释代码，直接运行生成的机器码。
   2. 解释性语言 源代码直接被解释器执行，无需编译成机器码。
3. **性能：** 
   1. 由于代码在执行之前已经经过了编译过程，编译型语言的执行速度通常较快，因为机器码的执行效率更高。
   2. 解释性语言的执行速度通常较慢，因为每次执行代码都需要解释器进行解释和执行。
4. **开发效率：** 
   1. 编译型语言需要经过编译过程，因此开发的迭代速度相对较慢。每次修改代码后都需要重新编译。
   2. 解释性语言由于无需编译过程，开发的迭代速度相对较快。修改代码后可以立即运行。

### 虚拟内存的作用，实现原理

#### 作用

**虚拟内存简单来说就是把外存当作内存来使用，便于缓解物理内存压力的不足。**所有运行在计算机上的程序都需要通过内存来执行，如果运行的程序占用了大量的内存，将导致内存耗尽。为了解决这个问题，采用了虚拟内存技术，当内存耗尽时，计算机会自动调用硬盘作为内存来缓解内存紧张。**当计算机运行程序或运行所需随机内存不足时，此时虚拟内存就来进行充当数据存储的任务了**

#### 原理

**虚拟存储器由硬件与操作系统自动地实现存储器信息的调度与管理**虚拟内存是给每一个程序设置一个“连续”的虚拟地址空间，把这个地址空间分成若干页，这些页具有连续的地址范围，并在程序运行过程中动态地映射到物理内存中。当程序引用到物理内存地址空间时，硬件就会立刻执行相应的映射，当程序引用到一个地址空间之外的地址空间时，操作系统负责把丢失的部分装入物理内存，并重新执行失败指令。

**虚拟内存的调度方式一般可以分为页式调度、段式调度、段页式调度，不同的调度方式也有着不同的区别。**具体如下：

**页式调度：**

在页式虚拟存储器中，把虚拟空间划分成相同大小的页面，虚拟地址可以由页面表格转化为实体地址。每一个程序都有一个页表，其中的每一个空页数都有一个入口，这个入口至少包括了这个虚页的主存储器（实际页数），并将其用作实际地址的更高的域；将实页编号和虚拟位置的页面内位址合并，就会生成一个完全的实际位址，用以存取主存储器。

**段式调度：**

在段式虚拟存储器中，将虚拟位址分为段数和区段内部位址。每一程式设定一段表，段资料表的每一栏位都包含三个栏位：有效位元（表示区段是否已调至主存）、段起址（区段在实存中的首位址）及段长（纪录区段的实际长度）。

**段页式调度：**

段页式虚拟存储器是段式虚拟存储器和页式虚拟存储器的结合。首先将实存等分为几个页面，在一个片断的虚拟存贮器中，将一个程序按逻辑结构分割开来，然后根据实际页面的大小，对每个页面进行分类，并根据页面的不同，对各个页面进行输入和输出。

### 进程的内存分布

![img](面经汇总.assets/202205212344868.png)

用户空间内存，从**低到高**分别是 7 种不同的内存段：

- 程序文件段，包括二进制可执行代码；
- 已初始化数据段，包括静态常量；
- 未初始化数据段，包括未初始化的静态变量；
- 堆段，包括动态分配的内存，从低地址开始向上增长；
- 文件映射段，包括动态库、共享内存等，从低地址开始向上增长（跟硬件和内核版本有关）
- 栈段，包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 `8 MB`。当然系统也提供了参数，以便我们自定义大小

#### 函数调用时栈区的状态

栈区主要用于存储函数的局部变量、函数参数、返回地址和临时数据等信息。下面是函数调用期间栈区的一般状态变化：

1. **调用前**：在函数调用之前，栈顶指针指向当前函数的栈帧的顶部。这个栈帧包含了函数的局部变量、参数、返回地址等信息。
2. **函数调用**：当一个函数被调用时，会执行以下步骤：
   - 将函数的参数压入栈中，以便函数在栈中获取参数值。
   - 将返回地址（调用该函数之后要返回的地址）压入栈中。
   - 分配空间用于存储函数的局部变量。
   - 更新栈顶指针，指向新的栈帧。
3. **函数执行**：在函数执行期间，栈帧内的局部变量被使用，可能会被修改。其他栈帧的信息保持不变，等待函数执行完成后恢复。
4. **函数返回**：当函数执行完成后，会执行以下步骤：
   - 从栈中弹出局部变量，释放栈帧内的内存。
   - 弹出返回地址，以便返回到调用函数的正确位置。
   - 更新栈顶指针，回到调用函数的栈帧。

### 乐观锁和悲观锁

乐观锁（Optimistic Locking）和悲观锁（Pessimistic Locking）是在并发编程中用于处理多个线程或进程访问共享资源的两种不同策略。它们的基本思想和应用场景有所不同。

**乐观锁（Optimistic Locking）：**

乐观锁的基本思想是，假设在大多数情况下，资源的访问是不会发生冲突的。因此，在读取资源时不会立即对资源进行加锁，而是在更新资源时再检查是否有冲突。

1. **实现方式：** 乐观锁一般通过版本号或时间戳来实现。在读取资源时，会同时获取一个版本号或时间戳。在更新资源时，会比较当前的版本号或时间戳是否与之前读取的一致，如果一致，说明资源未被修改，可以进行更新。
2. **适用场景：** 乐观锁适用于并发冲突较少的情况，当冲突较少时，避免频繁加锁可以提高性能。但是，如果冲突频繁，可能需要不断重试，会增加额外的开销。

**悲观锁（Pessimistic Locking）：**

悲观锁的基本思想是，假设资源的访问在任何时候都可能发生冲突。因此，在访问资源时会立即对资源进行加锁，确保在其他线程或进程修改时不会访问资源。

1. **实现方式：** 悲观锁通过互斥锁（Mutex）等机制来实现。在访问资源前，会获取互斥锁，如果资源已被其他线程持有，当前线程会被阻塞，直到资源可用。
2. **适用场景：** 悲观锁适用于并发冲突较多的情况，因为它保证了资源的独占性，避免了并发访问造成的问题。然而，频繁的锁竞争可能导致性能下降。

#### 用乐观锁实现数组的读写锁

```c++
std::vector<int> data;
std::atomic<int> version(0);

// 乐观锁读取数组
int optimisticRead(size_t index) {
    int localVersion;
    std::vector<int> localData;
    
    do {
        localVersion = version.load(std::memory_order_acquire);
        localData = data;
        // 访问数组，不需要加锁
    } while (localVersion != version.load(std::memory_order_acquire));
    
    return localData[index];
}

// 乐观锁更新数组
void optimisticUpdate(size_t index, int value) {
    std::unique_lock<std::shared_mutex> lock(rwLock);
    data[index] = value;
    version.fetch_add(1, std::memory_order_release);
}

```

### TCP的三次握手

1. **第一步：客户端发送 SYN（同步）报文：**

   客户端（Client）想要建立连接，首先会发送一个带有 SYN 标志（标志位）的报文段，这个报文段的序号为 A（可以理解为随机的一个序号）。

2. **第二步：服务器发送 SYN + ACK 报文：**

   服务器（Server）收到客户端的 SYN 报文后，会作出响应。服务器发送一个带有 SYN 和 ACK 标志的报文段，确认收到了客户端的连接请求。服务器的确认序号为 A+1，表示已经成功收到了客户端发送的序号为 A 的报文。

3. **第三步：客户端发送 ACK 报文：**

   客户端收到服务器的 SYN+ACK 报文后，会发送一个带有 ACK 标志的报文段作为确认。此时，客户端的确认序号为服务器的序号 + 1，客户端的序号为之前的 A+1。

#### 只握手两次的问题

如果只进行两次握手，那么服务器只能确认客户端的请求，但是客户端无法确认服务器是否已经收到自己的请求，从而无法保证连接的可靠性。

1. **连接复用问题：** 如果只进行两次握手，那么客户端发送的连接请求（SYN报文）可能会被网络中的延迟数据包误认为是新的连接请求，从而导致服务器分配资源去处理这些无效的连接请求。这可能会对服务器的资源产生负担，影响服务器的性能。
2. **半开连接问题：** 如果只有两次握手，客户端发送的连接请求在服务器端接收到之前，服务器就发送确认回复（SYN+ACK报文），此时连接即被认为已建立。但是如果客户端并不接受或丢弃了服务器的回复，这就会造成服务器认为连接已建立，但实际上客户端并未意识到，从而导致资源浪费。
3. **安全性问题：** 三次握手中的第三次握手（服务器发送的确认）能够确保客户端的请求被正式接受，从而防止某些恶意主机伪造连接。如果只有两次握手，就可能更容易受到连接伪造攻击。

#### 四次挥手

1. **第一步：客户端发送 FIN 报文：**

   客户端希望终止连接时，会发送一个带有 FIN（终止）标志的报文段，这个报文段的序号为 A。这表示客户端不会再向服务器发送数据，但仍然可以接收服务器的数据。

2. **第二步：服务器发送 ACK 报文：**

   服务器收到客户端的 FIN 报文后，会发送一个带有 ACK 标志的报文段，确认收到了客户端的终止请求。服务器的确认序号为 A+1，表示已经成功接收了客户端发送的序号为 A 的报文。

3. **第三步：服务器发送 FIN 报文：**

   服务器也可能希望终止连接，当它完成数据传输后，会发送一个带有 FIN 标志的报文段，这个报文段的序号为 B。

4. **第四步：客户端发送 ACK 报文：**

   客户端收到服务器的 FIN 报文后，会发送一个带有 ACK 标志的报文段，确认收到了服务器的终止请求。客户端的确认序号为 B+1，表示已经成功接收了服务器发送的序号为 B 的报文。

   ### 聚簇索引是什么

   聚簇索引（Clustered Index）是数据库中一种特殊类型的索引结构，它对表的行进行物理排序，同时决定了表在磁盘上的存储顺序。与其他类型的索引不同，聚簇索引实际上定义了表的物理存储方式，而不仅仅是为了加快查询速度。

   在聚簇索引中，数据行按照聚簇索引的顺序存储在磁盘上的数据页中。这意味着，如果表按照某一列创建了聚簇索引，那么这个列的值将会决定数据在磁盘上的物理位置。因此，聚簇索引的叶子节点实际上存储了整个数据行的内容，而不仅仅是索引列的值。

   以下是一些关键特点和优缺点：

   **特点：**

   - 聚簇索引对于频繁地范围查询、排序和分组查询非常有效，因为相邻的行在磁盘上也是相邻存储的，可以减少磁盘的读取。
   - 表中只能有一个聚簇索引，因为它决定了表的物理排序。
   - 插入、更新和删除数据行时，因为要维护数据的物理顺序，可能会引发页的分裂和合并，从而影响性能。

   **优点：**

   - 范围查询、排序等操作效率高，因为数据在磁盘上是连续存储的。
   - 聚簇索引可以减少存储空间，因为数据行的索引列和数据本身存储在同一位置。

   **缺点：**

   - 插入、更新和删除操作可能需要更多的维护开销，因为可能需要调整数据的物理顺序。
   - 当数据的插入顺序和聚簇索引的顺序不一致时，可能导致数据页的频繁分裂和合并，影响性能。

   ## 百度知识图谱部

### 指针与引用的区别

- 指针是一个变量，存储的是一个地址，引用跟原来的变量实质上是同一个东西，是原变量的别名
- 指针可以有多级，引用只有一级
- 指针可以为空，引用不能为NULL且在定义时必须初始化
- 指针在初始化后可以改变指向，而引用在初始化之后不可再改变
- sizeof指针得到的是本指针的大小，sizeof引用得到的是引用所指向变量的大小
- 当把指针作为参数进行传递时，也是将实参的一个拷贝传递给形参，两者指向的地址相同，但不是同一个变量，在函数中改变这个变量的指向不影响实参，而引用却可以。
- 引用本质是一个指针，同样会占4字节内存；指针是具体变量，需要占用存储空间（，具体情况还要具体分析）。
- 引用在声明时必须初始化为另一变量，一旦出现必须为typename refname &varname形式；指针声明和定义可以分开，可以先只声明指针变量而不初始化，等用到时再指向具体变量。
- 引用一旦初始化之后就不可以再改变（变量可以被引用为多次，但引用只能作为一个变量引用）；指针变量可以重新指向别的变量。
- 不存在指向空值的引用，必须有具体实体；但是存在指向空值的指针。

#### 在传递函数参数时，什么时候该使用指针，什么时候该使用引用呢

- 需要返回函数内局部变量的内存的时候用指针。使用指针传参需要开辟内存，用完要记得释放指针，不然会内存泄漏。而返回局部变量的引用是没有意义的
- 对栈空间大小比较敏感（比如递归）的时候使用引用。使用引用传递不需要创建临时变量，开销要更小
- 类对象作为参数传递的时候使用引用，这是C++类对象传递的标准方式

### 数据库ACID介绍

ACID 是数据库事务的四个关键特性的首字母缩写，它们分别代表了数据库管理系统中确保数据一致性和可靠性的核心原则。这四个特性是：

1. **原子性（Atomicity）：** 原子性指的是一个事务被视为一个不可分割的最小单元，要么全部执行成功，要么全部不执行。如果事务中的任何一个步骤失败，整个事务都会被回滚到初始状态，保证数据库中的数据不会处于中间状态。
2. **一致性（Consistency）：** 一致性要求在事务执行前和执行后数据库的状态必须保持一致。换句话说，一个事务在执行前和执行后，数据库的完整性约束和业务规则都必须保持不变。
3. **隔离性（Isolation）：** 隔离性确保并发执行的事务不会相互干扰，每个事务都认为它是唯一在操作数据的。这防止了并发事务之间的数据争用和不一致。
4. **持久性（Durability）：** 持久性确保一旦事务提交，其对数据库的改变将会永久保存，即使在系统故障的情况下也不会丢失。这通常涉及到将事务的改变写入到物理存储设备中。

## C++的内存分配方式

**new：** `new` 运算符是C++中用于动态分配内存的方式。它不仅分配了内存空间，还调用了构造函数来初始化对象。`new` 返回指向分配内存的指针。

**malloc：** `malloc` 是C语言中的内存分配函数，也可以在C++中使用。它只分配内存空间，不调用构造函数。需要手动释放内存并调用析构函数。

### 内存空间分区

- **堆（Heap）：** 堆用于动态分配内存，即运行时根据需要分配和释放内存。它通常用于存储动态分配的对象和数据结构。
- **栈（Stack）：** 栈用于存储函数的局部变量和函数调用的上下文信息。每个函数调用都会在栈上创建一个称为栈帧的区域，包含了函数的参数、局部变量以及函数调用的返回地址等信息。
- **代码区（Text Segment）：** 代码区存储程序的可执行指令。这部分内存通常是只读的，存储程序的机器码。
- **数据区（Data Segment）：** 数据区用于存储全局变量和静态变量。其中的初始化数据存储在数据区的已初始化数据段，未初始化数据存储在未初始化数据段（BSS段）。

### 怎样判断电脑的位数？电脑位数的作用？

C/C++ 中可以使用 `sizeof(void*)` 来判断指针的大小，从而推断出系统的位数

电脑的位数指的是处理器的寻址位数，通常有 32 位和 64 位两种。这个概念与操作系统的位数并不完全相同。在 32 位系统中，处理器可以一次寻址 32 位（4 字节）内存地址，而在 64 位系统中，可以一次寻址 64 位（8 字节）内存地址。

### 怎样将大于号重载为小于号，操作符重载的生效范围

```C++
bool operator>(const MyNumber& other) const
```

- 运算符重载仅对自定义的类类型有效，无法直接对基本数据类型进行重载。
- 运算符重载的作用范围仅限于类的内部和友元函数。也就是说，重载运算符的定义必须在类的作用域内，或者可以在类外部定义为该类的友元函数。

### 七层网络协议

- 物理层：底层数据传输，如网线；网卡标准。
- 数据链路层：定义数据的基本格式，如何传输，如何标识；如网卡MAC地址。
- 网络层：定义IP编址，定义路由功能；如不同设备的数据转发。
- 传输层：端到端传输数据的基本功能；如 TCP、UDP。
- 会话层：控制应用程序之间会话能力；如不同软件数据分发给不同软件。
- 表示层：数据格式标识，基本压缩加密功能。
- 应用层：各种应用软件，包括 Web 应用。

#### 数据链路层怎样保证包的正确性

数据链路层使用帧的校验和机制确保数据包的正确性

#### 传输层的功能

负责数据的可靠传输

## 字节AILAB

### http和https的区别，加密方式

1、HTTP协议传输的数据都是未加密的，也就是明文的，因此使用HTTP协议传输隐私信息非常不安全， HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，要比http协议安全。

2、https协议需要到ca申请证书，一般免费证书较少，因而需要一定费用。

 3、http和https使用的是完全不同的连接方式，用的端口也不一样，前者是80，后者是443。

SSL代表安全套接字层。它是一种用于加密和验证应用程序（如浏览器）和Web服务器之间发送的数据的协议。 身份验证 ， 加密Https的加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制。

SSL/TLS协议作用：认证用户和服务，加密数据，维护数据的完整性的应用层协议加密和解密需要两个不同的密钥，故被称为非对称加密；加密和解密都使用同一个密钥的

对称加密：优点在于加密、解密效率通常比较高 ，HTTPS 是基于非对称加密的， 公钥是公开的

#### SSL怎么工作保证安全

（1）客户端向服务器端发起SSL连接请求； 

（2） 服务器把公钥发送给客户端，并且服务器端保存着唯一的私钥 

（3）客户端用公钥对双方通信的对称秘钥进行加密，并发送给服务器端 

（4）服务器利用自己唯一的私钥对客户端发来的对称秘钥进行解密， 

（5）进行数据传输，服务器和客户端双方用公有的相同的对称秘钥对数据进行加密解密，可以保证在数据收发过程中的安全，即是第三方获得数据包，也无法对其进行加密，解密和篡改。

RSA和ECDHE算法

### 四次挥手流程

1. **第一次挥手（FIN-WAIT-1）：** 客户端发送一个TCP连接关闭请求，将标志位设置为FIN（Finish）。此时客户端进入 FIN-WAIT-1 状态，等待服务器的确认。
2. **第二次挥手（CLOSE-WAIT）：** 服务器收到客户端发送的FIN请求后，响应一个ACK（Acknowledgment）确认报文，并进入 CLOSE-WAIT 状态。此时服务器可以继续向客户端发送数据。
3. **第三次挥手（LAST-ACK）：** 当服务器发送完所有数据后，它会发送一个FIN请求给客户端，表示服务器的数据发送完毕。服务器进入 LAST-ACK 状态，等待客户端的确认。
4. **第四次挥手（TIME-WAIT）：** 客户端收到服务器的FIN请求后，发送一个ACK确认报文，进入 TIME-WAIT 状态。在此状态下，客户端等待一段时间（称为时间等待，TIME-WAIT状态），以确保服务器收到了ACK确认报文，然后客户端才能释放资源。

#### time_wait和wait_close分别在哪一端

TIME-WAIT 状态在客户端一侧。这是为了确保在关闭连接后，服务器可能还会收到客户端最后一个ACK的重传，如果客户端在TIME-WAIT状态，它可以正确地响应服务器的重传，避免了出现旧的连接请求影响到新的连接。

wait_close是在服务端，等待自己的数据发送结束

#### 两个状态过多，可能是因为什么

- **TIME-WAIT 状态过多：** TIME-WAIT 状态的持续时间为连接断开后 2MSL（Maximum Segment Lifetime，最大报文寿命），用于确保所有报文都在网络中消失。如果短时间内有大量连接断开，可能会导致TIME-WAIT状态积累过多，浪费系统资源。可以通过调整系统参数来减少TIME-WAIT状态的持续时间。
- **CLOSE-WAIT 状态过多：** CLOSE-WAIT 状态表示服务器等待关闭连接，可能是由于客户端没有正确关闭连接而导致服务器一直等待。这可能是客户端代码存在问题，没有正确关闭连接，导致服务器一直等待关闭。

### 如果服务器端流量窗口已满，客户端处于什么状态

客户端在发送数据给服务器端时，会根据服务器端的通知，调整发送速率，以避免过快地发送数据导致服务器端的缓冲区溢出。如果服务器端的流量窗口已满，即服务器暂时无法处理更多的数据，客户端会暂时停止发送数据，并进入等待状态，直到服务器端再次通知可以接受数据为止。

客户端的等待状态在TCP协议中通常是通过“滑动窗口”机制来实现的。滑动窗口表示服务器能够接受的数据量，而流量窗口则表示服务器端当前能够接受的剩余数据量。客户端会根据服务器端发送的通知，不断调整滑动窗口大小，以确保发送的数据不会超出服务器的处理能力。

#### 流量控制和拥塞控制的区别

- 流量控制属于通信双方协商；拥塞控制涉及通信链路全局。
- 流量控制需要通信双方各维护一个发送窗、一个接收窗，对任意一方，接收窗大小由自身决定，发送窗大小由接收方响应的TCP报文段中窗口值确定；拥塞控制的拥塞窗口大小变化由试探性发送一定数据量数据探查网络状况后而自适应调整。

#### TCP拥塞控制算法

TCP（Transmission Control Protocol）的拥塞控制算法是为了在网络拥塞的情况下，确保数据的可靠传输，并且避免进一步加剧网络拥塞。TCP的拥塞控制算法包括以下几种主要机制：

1. **慢启动（Slow Start）：** 在连接刚建立时，TCP会以一个较小的发送窗口开始发送数据，然后逐渐增加发送窗口大小，以测试网络的拥塞程度。如果没有遇到拥塞，发送窗口大小会指数级增加。
2. **拥塞避免（Congestion Avoidance）：** 在慢启动阶段后，TCP进入拥塞避免阶段，发送窗口大小增加的速率减缓，以避免过快增加导致网络拥塞。在这个阶段，发送窗口的增加是线性的。
3. **快重传（Fast Retransmit）：** 如果接收端收到了失序的报文，它会发送一个重复的ACK（选择确认，SACK），表明它需要缺失的报文。发送端在收到一定数量的重复ACK后（通常是3个），会认为有一个报文丢失，会立即重传这个报文，而不必等待超时。
4. **快恢复（Fast Recovery）：** 在快重传后，TCP会进入快恢复阶段，继续发送数据，但是发送窗口大小减半，然后线性增加。这有助于在网络恢复后重新逐步增加发送速率。
5. **超时重传（Timeout Retransmission）：** 如果发送端在等待ACK的过程中超过了一个合理的时间，即超时，发送端会假定某个报文已丢失，然后重传该报文。

### TCP的粘包问题，怎样解决

TCP粘包问题是指发送方在发送数据时，由于TCP的特性，多个小的数据包可能被合并成一个大的数据包，或者一个大的数据包被拆分成多个小的数据包，从而导致接收方难以准确地区分每个数据包的边界

**定长消息、特殊字符分隔、消息长度头部**



### 怎样让程序在后台运行

1. 使用 `&` 符号：在命令的末尾添加 `&` 符号，可以将程序在后台运行。
2. 使用 `nohup` 命令：`nohup` 命令可以在后台运行程序，并忽略挂断信号，这意味着即使终端关闭，程序也会继续运行。
3. 使用tmux



### 进程的通信方式

在操作系统中，不同的进程之间需要进行通信以实现数据交换、同步操作等。进程间通信（Inter-Process Communication，IPC）是实现这种通信的技术和机制。

1. **管道（Pipe）：** 管道是一种半双工的通信方式，适用于有亲缘关系的进程（如父子进程）。管道分为匿名管道（无名管道）和命名管道。匿名管道只能在有亲缘关系的进程之间使用，而命名管道可以在不同进程之间使用。
2. **命名管道（Named Pipe）：** 命名管道是一种允许无亲缘关系的进程之间通信的方式。它通过文件系统中的特殊文件来实现。
3. **消息队列（Message Queue）：** 消息队列是一种在内核中维护的消息链表，允许进程通过发送和接收消息进行通信。不同进程可以通过消息队列进行异步通信。
4. **共享内存（Shared Memory）：** 共享内存允许多个进程共享同一块物理内存区域，从而实现高效的数据交换。然而，由于共享内存需要显式地进行同步和互斥操作，因此需要小心处理以避免竞争条件。
5. **信号量（Semaphore）：** 信号量是一种用于进程同步和互斥的机制。它可以用来控制多个进程对共享资源的访问。
6. **套接字（Socket）：** 套接字是一种在网络通信中使用的进程间通信方式，可以在同一台机器上或不同机器之间进行通信。套接字通信可以通过不同的协议实现，如TCP或UDP。
7. **RPC（Remote Procedure Call）：** RPC是一种允许程序在不同地址空间调用远程过程的通信方式。它允许进程在远程执行函数，就像调用本地函数一样。
8. **消息传递（Message Passing）：** 消息传递是一种通过发送和接收消息来实现通信的方式。它可以是基于内存的，也可以是基于网络的。

### Socket和本地通信有什么不同

Socket通信基于网络协议（如TCP和UDP），它使用IP地址和端口号来标识通信的双方，并且可以通过套接字（Socket）进行数据传输。这种通信方式适用于分布式系统和远程通信。

### 四种cast转换方式


在C++中，有四种常见的类型转换方式，也称为C++的四种转换（Four Casts），分别是：

1. **静态转换（Static Cast）：**

   静态转换是最常见的转换，用于基本的类型转换，例如整数之间的转换、非常量指针之间的转换等。它在编译时进行，不提供运行时类型检查。可以用于类型之间的相关转换，但需要注意类型转换的合理性，否则可能导致错误。

   ```C++
   cppCopy codeint a = 10;
   double b = static_cast<double>(a);  // 静态转换，从int转换为double
   ```

2. **动态转换（Dynamic Cast）：**

   动态转换主要用于类层次结构中的指针或引用之间的转换，它在运行时执行，包含类型检查。如果基类指针指向子类对象，可以使用动态转换将其转换为子类指针，但需要注意转换的合法性，否则会返回空指针（对于指针）或抛出异常（对于引用）。

   ```C++
   cppCopy codeBase* basePtr = new Derived;
   Derived* derivedPtr = dynamic_cast<Derived*>(basePtr);  // 动态转换，从基类指针到子类指针
   ```

3. **常量转换（Const Cast）：**

   常量转换用于添加或移除const修饰符，主要用于指针和引用。它可以将指向非常量的指针转换为指向常量的指针，或者反之。常量转换不会修改对象本身，只是改变指针或引用的类型。

   ```C++
   cppCopy codeconst int* ptr = new int;
   int* nonConstPtr = const_cast<int*>(ptr);  // 常量转换，从const指针到非const指针
   ```

4. **重新解释转换（Reinterpret Cast）：**

   重新解释转换允许将一个指针或引用重新解释为不同类型的指针或引用。它通常用于低层次的转换，例如将指针转换为整数。这种转换几乎没有类型检查，应该谨慎使用，因为可能导致不可预测的结果。

   ```C++
   cppCopy codeint value = 42;
   double* doublePtr = reinterpret_cast<double*>(&value);  // 重新解释转换，从int指针到double指针
   ```

### 重载和重写

重载（Overloading）和重写（Override）是两种不同的概念，分别用于描述不同的情况。

**重载（Overloading）：**

重载指的是在同一个作用域内，对一个函数名使用不同的参数列表来定义多个函数。这些函数可以有不同的参数类型、个数或顺序，但它们必须有相同的函数名。重载使得我们可以根据不同的输入情况来调用适当的函数。

**重写（Override）：**

重写是指在派生类中重新定义基类中的虚函数，以便在派生类对象上调用时能够调用到派生类中的函数实现。重写需要满足特定的条件，如基类函数必须是虚函数，派生类中的函数声明必须与基类函数相匹配（包括参数列表和返回类型），同时使用 `override` 关键字可以增强代码的可读性和安全性。



# 窝自己

## 快手C++搜索引擎架构师

### C++11新特性

### linux内存管理方式

虚拟内存（Virtual Memory）是一种计算机内存管理技术，它允许程序使用比物理内存更大的内存空间，将程序的运行看作是在一个更大的内存空间中进行，而实际上只有部分数据和代码被加载到物理内存中。虚拟内存的主要目的是提供更大的内存空间，以支持大型应用程序，并且在不同程序之间提供隔离和保护。

1. **虚拟地址空间：** 每个进程都有自己的虚拟地址空间，它是一个连续的地址范围，从0开始，通常是32位或64位。虚拟地址空间被分为多个区域，如代码区、数据区、堆区、栈区等。
2. **页：** 虚拟内存将物理内存划分为大小固定的页（通常为4KB或8KB），同时也将虚拟地址空间划分为与物理内存页相同大小的页。这样，虚拟地址空间中的每一页可以映射到物理内存中的一页，以实现数据的加载和交换。
3. **页表：** 为了实现虚拟地址到物理地址的映射，操作系统使用页表来维护虚拟地址与物理地址之间的关系。页表中记录了每个虚拟页与对应的物理页的映射关系。当程序访问虚拟内存时，操作系统根据页表将虚拟地址转换为物理地址。
4. **分页和交换：** 当程序访问一个虚拟页，但该页不在物理内存中时，操作系统会通过分页机制将虚拟页加载到物理内存中，如果物理内存不足，操作系统会将不常用的页面换出到磁盘的交换空间，以便为新的页面腾出空间。
5. **内存保护和隔离：** 虚拟内存提供了内存保护和隔离的功能，不同的进程拥有独立的虚拟地址空间，一个进程无法直接访问其他进程的内存，从而实现了数据的隔离和保护。

### 为什么tcp安全

TCP（Transmission Control Protocol）是一种面向连接的、可靠的传输层协议，它通过一系列机制来保证数据的安全传输。以下是TCP如何保证安全传输的主要机制：

1. **确认和重传（Acknowledgment and Retransmission）：** TCP使用确认机制来保证数据的可靠传输。接收方在收到数据后会发送确认（ACK）给发送方，表示数据已接收。如果发送方在一定时间内没有收到确认，就会认为数据丢失，触发重传机制，重新发送丢失的数据。
2. **序列号和流量控制（Sequence Number and Flow Control）：** TCP在传输的每个数据段中都包含了一个序列号，接收方可以根据序列号按照正确的顺序重组数据。此外，TCP还通过滑动窗口的机制来实现流量控制，确保接收方不会被发送方的数据淹没。
3. **连接建立和终止（Connection Establishment and Termination）：** TCP在数据传输前会通过三次握手建立连接，确保双方的通信状态正确。在通信结束时，通过四次挥手终止连接，保证数据完整传输。
4. **超时和重传时间设置（Timeout and Retransmission Timer）：** TCP维护一个重传定时器，当发送数据后，如果在一定时间内没有收到确认，就会认为数据可能丢失，触发重传。超时时间的设置需要根据网络的延迟和可靠性来平衡。
5. **拥塞控制（Congestion Control）：** TCP使用拥塞控制机制来防止网络拥塞。如果网络拥塞，TCP会逐渐降低发送速率，避免发送过多的数据导致更严重的拥塞。
6. **首部校验和（Header Checksum）：** TCP在数据段的首部添加了校验和，用于检测数据段是否在传输过程中被篡改。

### 为什么栈比堆快

1、有寄存器直接对栈进行访问（[esp](https://so.csdn.net/so/search?q=esp&spm=1001.2101.3001.7020)，ebp），而对堆访问，只能是间接寻址。

也就是说，可以直接从地址取数据放至目标地址；使用堆时，第一步将分配的地址放到寄存器，然后取出这个地址的值，然后放到目标地址。

2、栈中数据cpu命中率更高，满足局部性原理。

3、栈是编译时系统自动分配空间，而堆是动态分配（运行时分配空间），所以栈的速度快。

4、栈是先进后出的队列结构，比堆结构相对简单，分配速度大于堆。



# 红黑树

### 双红优化

1. 叔叔节点黑色：调整完根黑叶子红
   1. 同侧p为根
   2. 异侧x为根往叔叔方向旋转
2. 叔叔节点红色：
   1. 变黑后提高高度递归

### 双黑优化

1. 兄弟节点是黑色并且兄弟节点有红色
   1. 从红色节点往上转
2. 兄弟节点是黑色并且兄弟节点没红色
   1. 兄弟变红并且查父亲，变红或者递归
3. 兄弟节点是红色
   1. 往这边转，同时递归处理







